{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7NiAluOoe6xD"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zipref=zipfile.ZipFile('/content/drive/MyDrive/ISL/ISLEnglishTestDataset.zip')\n",
        "zipref.extractall(path=\"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cuOWhwRR24kH"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zipref=zipfile.ZipFile('/content/drive/MyDrive/ISL/ISLEnglishDataset.zip')\n",
        "zipref.extractall(path=\"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4BtdK3IxF8x",
        "outputId": "f5d18694-712b-498a-c130-d9338db0664a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m930.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_applications) (1.23.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_applications) (3.9.0)\n",
            "Installing collected packages: keras_applications\n",
            "Successfully installed keras_applications-1.0.8\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m739.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n",
            "Collecting image-classifiers\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from image-classifiers) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (1.23.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (3.9.0)\n",
            "Installing collected packages: image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_applications\n",
        "!pip install keras_preprocessing\n",
        "!pip install image-classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbE8cenuodlE",
        "outputId": "61539d88-4e52-4075-bc57-c7d0d37695b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11391 images belonging to 25 classes.\n",
            "Found 623 images belonging to 25 classes.\n",
            "Epoch 1/20\n",
            "356/356 [==============================] - 349s 977ms/step - loss: 1.3682 - accuracy: 0.6265 - val_loss: 0.6108 - val_accuracy: 0.8186\n",
            "Epoch 2/20\n",
            "356/356 [==============================] - 343s 964ms/step - loss: 0.5359 - accuracy: 0.8502 - val_loss: 0.2664 - val_accuracy: 0.9342\n",
            "Epoch 3/20\n",
            "356/356 [==============================] - 342s 960ms/step - loss: 0.2193 - accuracy: 0.9391 - val_loss: 0.1306 - val_accuracy: 0.9647\n",
            "Epoch 4/20\n",
            "356/356 [==============================] - 336s 943ms/step - loss: 0.0839 - accuracy: 0.9788 - val_loss: 0.0298 - val_accuracy: 0.9952\n",
            "Epoch 5/20\n",
            "356/356 [==============================] - 340s 955ms/step - loss: 0.0393 - accuracy: 0.9902 - val_loss: 0.0425 - val_accuracy: 0.9904\n",
            "Epoch 6/20\n",
            "356/356 [==============================] - 339s 951ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.0106 - val_accuracy: 0.9984\n",
            "Epoch 7/20\n",
            "356/356 [==============================] - 330s 926ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.0175 - val_accuracy: 0.9952\n",
            "Epoch 8/20\n",
            "356/356 [==============================] - 330s 924ms/step - loss: 0.0583 - accuracy: 0.9827 - val_loss: 0.0385 - val_accuracy: 0.9872\n",
            "Epoch 9/20\n",
            "356/356 [==============================] - 331s 931ms/step - loss: 0.0361 - accuracy: 0.9899 - val_loss: 0.0199 - val_accuracy: 0.9952\n",
            "Epoch 10/20\n",
            "356/356 [==============================] - 333s 936ms/step - loss: 0.0317 - accuracy: 0.9907 - val_loss: 0.0344 - val_accuracy: 0.9952\n",
            "Epoch 11/20\n",
            "356/356 [==============================] - 327s 920ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0107 - val_accuracy: 0.9968\n",
            "Epoch 12/20\n",
            "356/356 [==============================] - 342s 959ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0116 - val_accuracy: 0.9952\n",
            "Epoch 13/20\n",
            "356/356 [==============================] - 333s 936ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.0328 - val_accuracy: 0.9904\n",
            "Epoch 14/20\n",
            "356/356 [==============================] - 329s 925ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 0.0353 - val_accuracy: 0.9888\n",
            "Epoch 15/20\n",
            "356/356 [==============================] - 333s 936ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "356/356 [==============================] - 327s 917ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
            "Epoch 17/20\n",
            "356/356 [==============================] - 329s 923ms/step - loss: 3.6581e-04 - accuracy: 1.0000 - val_loss: 1.4095e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "356/356 [==============================] - 335s 942ms/step - loss: 1.0332e-04 - accuracy: 1.0000 - val_loss: 8.8991e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "356/356 [==============================] - 327s 920ms/step - loss: 7.4016e-05 - accuracy: 1.0000 - val_loss: 6.5858e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "356/356 [==============================] - 332s 933ms/step - loss: 5.8083e-05 - accuracy: 1.0000 - val_loss: 5.1738e-05 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d0748377c10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "TrainDataGen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "TestDataGen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "TrainData=TrainDataGen.flow_from_directory(directory=\"/content/train\",target_size=(224,224),class_mode='categorical')\n",
        "TestData=TestDataGen.flow_from_directory(directory=\"/content/test\",target_size=(224,224),class_mode='categorical')\n",
        "model=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(2,input_shape=(224,224,3)),\n",
        "  tf.keras.layers.Conv2D(8,kernel_size=(3,3),activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "  tf.keras.layers.Conv2D(16,kernel_size=(3,3),activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(25,activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\"])\n",
        "model.fit(TrainData,epochs=20,validation_data=TestData,steps_per_epoch=len(TrainData),validation_steps=len(TestData))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model/classification_model')"
      ],
      "metadata": {
        "id": "hOfNg7rNzHnU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/saved_model/classification_model') # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "7TSEFR77Gvib"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}